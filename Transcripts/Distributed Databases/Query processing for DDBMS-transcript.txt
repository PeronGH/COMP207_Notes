This video is about query processing in distributed database management software. We will here discuss some issues that come up in query processing in distributed database management systems. So I will also provide you an example of how to do better than what you could do naively using these SIMM joints I've talked about a long while ago. So let me try to describe the issue with this query processing in distributed database management systems. So we have a query say here up in B and we try to answer it. Well if every piece of information we need to answer the query is already present in the database at B, we just do that to answer the query and we're good to go. However, and this is often the case, if you don't have all the information you need, you need to get information from elsewhere and bring it up to B. Or well you can also send information from B and bring it elsewhere and then answer the question there and just get the answer back. There are many ways of doing this. But doing this kind of thing is very slow because the network is even slower than your personal hard disk unless you have a really fast network. But again it will typically be slower because over there they might need to get it from the hard disk. So of course in the end you will end up paying quite a bit more than you would for hard disk. So you should try to reduce this as much as possible. So that's what the distributed database management systems try to do. The most expensive kind of thing you can do in these queries are these joints because it's the only example where you get more information than linear in the size of the tables, if you think about it. So let's see how to do joints smarter than what you could do naively. Let me start by showing you how to do a naive kind of join in a distributed database setting. So let's say we have two relations R and S, each placed at different sites. So R is stored at A and B stores S. And we then make a query at B about calculating the natural join of R and S. So what can we do? Well I think the most naive way of doing it is that site B simply asks site A to send them everything about R and then compute R natural join S at site B. It is very straightforward. So it basically looks like this. You have R over here and we send it along over to B and then you do the calculation. It is quite straightforward. So the issue with this approach is that this connection between the two sites might be quite slow. And especially because this R might be very big, so it can take quite a while to do this sending of everything. So what should we do instead? We should try to only send whatever we really need instead of all of R. And it turns out that we can do significantly better, at least in some cases. And we'll now see how to do that. If you spent quite a while thinking about what you really need here, as what you need from site A about R, you'll find that what you need is the left semi-join of R on S. So because I'm sure that many of you have forgotten everything about what the left semi-joints and the right semi-joints are, I'm going to remind you about it here and then proceed. So earlier when I described left semi-joints and right semi-joints, I was talking about it from the perspective of the where clause, because that's how you implement it in SQL. Here though, I'm going to discuss it from the perspective of police mail algebra, because it's a bit more condensed version of it, and it makes it clear why this is the thing we want. But I will also show it later why this is the thing we want. So let me come with some example of it, because as I said, I figure you likely have forgotten. R left semi-joint on S is R natural joint with the projection of the common attributes of R on S on S. So let's see how it works on an example, so it makes sense what's going on. Say we have two tables here, modules and lecturers, and we take the left semi-joint on modules on lecturers, then that gives us module of comp 105 and here equal to 1, and comp 201 and here equal to 2. Notice that comp 207 and here 2 is not there, because I'm not in the lecturers table. So basically that's how this left semi-joint work. So intuitively, if you think about it, the left semi-joint on R and S is a set of tables in R that join with at least one table in S in a natural joint. So that's sort of the idea, and this is precisely why we'll end up needing precisely this part of R. Basically, any other row you don't need, because, well, it's not going to join with anything in this. On the other hand, you do need everything about these rows that do join, because, well, it's what you need for the output. So let's try to use it on this example from earlier. So we have the same setup as before. We have side A storing R, we have side B storing S, and we then want to compute the natural joint of R and S at side B. So let's see how to do semi-joints and use them to compute this. So in essence, what we want to do is compute the left semi-joint at side A and send it over to B. To do that, we need something from B, so side A can compute that left semi-joint. What we need to send, it turns out, and I will show you why in a few seconds, is S prime, which is the common attributes of R and S, and the protection of the common attributes of R and S on S, to side A from side B. So this is what we send, and then side A can compute our left semi-joint S. This is because, if you go back a slide, you will see that the definition of our left semi-joint S was R, natural joint S prime, where S prime precisely had this definition. So this is why we need to send S prime in the first case to compute R prime as in the left semi-joint of R and S at side A. And now we can send that R prime to side B, like this. And now at side B, we have S and all the tuples from R that will appear in the output of a natural joint. And of course, if you think about it, these are the only tuples you need to compute a natural joint. You don't need all the ones that doesn't appear in the output anyway, because that means that they haven't matched on the common attributes. No reason to look at those. So at this point, we can compute R prime, natural joint S, which is then again R, natural joint S, because we have only eliminated the irrelevant tuples. So how much did that cost? Well, it cost the first send, which was of size S prime times however big each tuple in S prime was, plus what we sent the other way, which was R prime times however big a tuple in R prime were. The important question to ask yourself here is, is this an improvement, as in, is this better than the obvious approach? Well, the answer is, that depends. For instance, if the projection is much smaller than the full relation, say many duplicates get eliminated, then this can be better. It could also be that the size of the semi-joint is much smaller than the size of the size of R, and again, this will typically make it better. In general, you should have hopefully that the size of the common attributes in S plus the size of the semi-joint R on S should be smaller than R. In that case, you can probably hope that it's better, depending on how big the different sizes are. So, note though, that you can calculate if sending the projection on the common attributes on S is less than sending R, and if so, you can try. If you're unlucky, you end up sending twice as much, as in, if both the common attributes on S is close to the size of R, and the left semi-joint on R on S is close to R. In that case, it's roughly twice as bad as just sending everything, but otherwise it's less. So, this technique you can ensure only spending twice as much, which is of course bad, but you can spend much less. So, let me come back to some examples, where you can see that this technique can save you a huge amount of communication over your network. So, let me try to combine an example, where we can see this in action, as in, where we end up getting some amount of savings, or reducing this technique. So, here we have a film database, and an in-theaters database, spread out over the two sides. And now we want to compute here at side B, the natural join of the films, together the selection of the, where the city is Liverpool, and the date is the 3rd of December 2020, in theaters over here in side B. So, as we all know, nowadays there's basically no movie going, so probably even though this is just after the end of the lockdown here, there probably not be that many movies in the theaters. So, this full thing is probably quite small. However, the full film database could be quite big, so we might be able to get quite a bit of savings here, but we'll see. So, the procedure was that we, from B, send over the projection onto film title, which is the shared set of attributes in the two databases, and we send over the selection of city equal to Liverpool and date equal to the 3rd of December 2020 in theaters. We send that from B to A. And then at side A, we calculate r prime, which is films, left-semit join with s prime, and we send that back again. And then at side B, we output r prime, left-semit join with this query from before. So, how much are we sending back and forth? Well, we need some assumptions on this. So, say there's 10,000 movies, and because we all know that there will not be going many movies at that time, as I said, because of all this coronavirus, even though this is just after lockdown, let's say there's 20 movies, when we run some movies, so that sounds about right. And say we're using a thousand bytes per tableau, just to have a number for it. Now, the communication cost is then 20 plus 20 as in size of s prime plus size of r prime, and then multiplied by the size of a tableau, which was a thousand, and we get 40,000 out of that. If you're being a bit more careful about it, you might get less information sent back and forth, because, well, you are only sending the movie titles from A to B, so that should probably be less than a thousand bytes, but still, this 40,000 is definitely a reasonable estimate of this number. Now, what would the obvious approach be? Well, that would be sending the film's database, and that might, or that would require you to send 10,000 times this 1,000 or 10 million bytes. So 40,000 bytes is clearly much less than 10 million bytes, and therefore we can send it much faster. And again, as I said, if you're being more careful about the analysis here, we'll have an even larger saving, but this suffice to see that we can get quite large savings using this trick. So that was it for query processing. We saw that there are some new challenges here in distributed database management systems. When you talk about query processing, you need to figure out where the different relations are stored, and also what part of them are stored there, to decide what to do, what kind of queries, that's bits, and how to optimize, and so on. And we saw specifically how to use similar joints to sometimes get a more efficient query. If you're watching these videos in order, this will be the last video on the required part of distributed databases. There are some more videos, but they're not required. They are on what is called MapReduce, which is a special programming framework that fits somewhere between the distributed databases of this part, and the next topic, which is on NoSQL databases. So you can watch those videos or not. It's basically up to you. They're not required for the exam. Still, I think it's an interesting topic, so you might want to watch them.