In this video, we will see how we can ensure that we get no cascading rollbacks. In the last video, we started talking about cascading rollbacks, where we had to abort a transaction and this caused more and more transactions to abort. We could avoid rolling back transactions that had already committed by using these recoverable schedules. That meant that we could avoid breaking durability because of these cascading rollbacks, at least. However, cascading rollbacks have other issues than just breaking durability. They are also quite slow, so because you had to roll back all these many schedules, all these many transactions, and therefore probably end up doing them again later. So, this video will discuss how to avoid cascading rollbacks at all, not just the ones that might imply that durability is broken. So, let's see how to do that. So, I want to show first that these recoverable schedules can still do cascades. So, look for instance at this schedule. Here, if you look carefully, you will see there's only one read operation. It's reading something written by transaction one. And it's recoverable because transaction one commits before transaction two. Now, however, if we have that transaction one needs to be rolled back just before committing, well, this will also mean we'll need to roll back transaction two, because it read something written by transaction one. And this is like a scaling rollback, because someone not directly involved in the transaction getting supported will have to roll back as well. And yeah, we don't like that much, because it will take a while to get all of these transactions got away with. I mean, here of course there are only two transactions, but in general there could be any number of transactions you have to roll back, even if you have recoverable schedules. Specifically, all the ones already running right now. So, how do we avoid that? Well, it's fairly straightforward, really. We use the cascade_less schedules. So, we say our schedule is called cascade_less if each transaction in it reads only values that are written by transactions that have already committed. So, basically speaking, the way we avoid cascades is by ensuring that I access no dirty reading. And when you don't end up reading this dirty data, you don't get any cascading rollbacks. So, let's see an example here. See the principle here. This schedule here would be a recoverable schedule. The problem here is that transaction two writes something, transaction one reads it. This is a dirty read. And then transaction two ends up committing, and then transaction one is subcommitting. So, this is recoverable, but not cascade_less. If we instead swap these two things, this would be cascade_less, because now whatever is written by T2 is first read by T1 after T2 has committed. So, similarly as for recoverable schedules, we need to ensure that the log records read the disk in the order they were written in. So, if we didn't do that well, then we could still have cascades, because of us seeing something wrong in the log file. So, let's see some examples. Let's start with some which are not cascade_less. These are ES1 to ES4 from the previous video, and they are all not cascade_less, because they read uncommitted data from T1. Specifically, this v2 operation is reading Y, which is written by transaction one, and transaction one is first going to commit close to the end of the schedule. On the other hand, you could also easily make one of the schedules cascade_less by simply moving commit one just before the read operation, like we are doing here. Now, here this v2 operation now is reading something which is committed, because the commit statement for a transaction one is before this read operation. However, and this is something I want to point out, this schedule S5 down here is not serializable, and you could for instance see it, because it's not view serializable, as you saw in your first tutorial on ACID properties. So, let's see some properties of these cascade_less schedules. The first property I want to mention is that they are general recoverable. So, let's look at it. Let's prove it. We have a cascade_less schedule here, and it's going to write some data X in transaction two at some point, and some data point that data is written in transaction one. Now, because transaction one does an operation, we must have that the commit statement must come afterwards. Our read and write operation must be before the commit statement of the corresponding transaction. Now, we could maybe think, ah, can we have the commit statement for T2 even later? Well, no, because T2 must commit between writing from T2 route to X and T1 read 6, because otherwise you would not be cascade_less, and we were assuming that was the case for the schedule. So, therefore transaction two commits before transaction one. On the other hand, cascade_less schedules are in general not always serializable, as we saw on the last slide. So, we have seen that in some cases we do not have both things, but can we have both things? Can we have both no cascading at both, and serializability, well, it shouldn't really be a surprise, but yes, we can have that. The way we get both of these two things, as in both cascade_less and serializable, is going through something called strict schedules. A schedule is strict if, whenever it has transaction in it, reads or writes data, whatever transaction wrote to that data earlier has already committed. So, for instance, look at this schedule here. T2 writes something, T2 commits, and is afterwards written, read by transaction one, and then transaction one commits later on. Now, this is fine in a strict schedule, but it would not be fine if T1 wrote to X earlier, as in before this commit statement. The problem, as in this is fine in cascade_less schedules, but it's not fine in a strict schedule. And this is what we're going to see how to enforce. Now, what would have been fine would have been if we had exchanged a place for these two operations, so that T2 writes first to X, T2 commits, T1 writes to X, and T1 reads X and then commits later on. That would be a strict schedule. Or at least these operations would not be a strict schedule. Of course, like before, the log records have to read the disk in the right order. So, let's talk about how we do it. We use something called strict two-phase logging. So, it's the most popular variant of this two-phase logging we saw earlier, this 2PL, and it enforces both conflict serializability as well as strict schedules, and therefore cascade-less schedules. So, the strict logging condition in addition to the two-phase logging condition, as in that all log operations must be before all on log operations, is that T, intersection T, must not release any log that allows T to write data until T has committed or aborted, and a commit or abort log record has been written to disk. So, you must have first a commit, and then you must release the logs, if this log allows you to write data. So, for simple logs, that means any kind of log should first be released after commit statements, and for shared and exclusive logs, I'm just talking about exclusive logs. So, you're allowed to release the shared logs before the commit statement, even in strict two-phase logging. So, let's see some examples of this. We have this transaction here. It's a 2PL transaction. You can see that all log statements come before every on log statement. Therefore, it's 2PL. And to do ondo logging, we assume that the commit statement writes all log records to disk, writes all modified database items to disk, and writes the commit record to disk. However, this schedule here is not a strict 2PL. This is because it unlocks the two variables before it has committed. So, let's look at another example. This new transaction, d_prime, and as you can see, it's basically the same transaction as before, except we have moved the on log statements down to until after commit statement. We have the commit statement first, and then we have the to log, the on log statements afterwards. And this new transaction here is strict 2PL transaction. And therefore, it will end up ensuring strict and conflict serializability. And again, I want to highlight here, logs are only released after you have fully committed everything, and everything has been written onto the disk in regards to ondo logging at least. So, let's look at an example where we have both shared exclusive logs. So, this schedule here is not strict 2PL. It's, even though it's releasing a log here in the middle, this is okay. This is okay, because that log was only a shared log. You are allowed to do release logs that are not able to write data, well, whenever you can, while still following 2PL. However, since Y is an exclusive log, we are first allowed to release it after we have completed it. To follow this strict 2PL. As the name also suggests, a strict two-phase logging enforces both conflict serializability, which is easy to see, because it requires all the requirements from two-phase logging plus some more. And it's strict. We haven't seen strict yet, so let's check that it's strict also. So, we have a schedule here. At some point, say, this transaction 1 is going to write some data 2x, and it's over writing something written by transaction 2. Now, for this to work, we must have an exclusive log in transaction 2 on X, because otherwise transaction 2 cannot write to it. And similarly for transaction 1, it must have earlier an exclusive log on X. Now, because transaction 2 was earlier, that means we must have unlocked X in between these two things, because otherwise transaction 1 cannot have the exclusive log on X. So, we must have this unlock X here earlier than the exclusive log in transaction 2. Now, that means, because of this strict logging condition, we must have that the commit statement for transaction 2 must be before the on on log of X. Basically, we have also the same argument, if we had instead of having written to X, we had read from X here, because again we need the log on X, in that case just the shared log, though. But still, you will need the log on X, which was earlier an exclusive log, you need it unlocked, and therefore it's basically the same argument, even if we had written a read from X instead of written to X in transaction 1. And therefore, we see that our schedule here, our strict two-phase logging schedule here, is also a strict schedule, as the name suggests. So, let's see how all of these different schedules relate to each other, and different types of schedules. Let's start with serial and serializable schedules. We know that the serial schedules are some subset of the serializable schedules, basically by definition. We have seen the recoverable schedules. Well, some schedules, and we have seen this, are recoverable, but not serializable, and some serializable schedules are not recoverable. But still, all the serial schedules are. We have seen cascadeless schedules, all serial schedules are cascadeless, and all cascadeless schedules are recoverable, but some cascadeless schedules are serializable, and some are not. And similarly, we have seen that some schedules are the co-operant serializable, but not cascadeless. We have also seen the strict schedules generated by strict 2PL, and all of the strict schedules are a special case of cascadeless schedules, and they're also all serializable schedules, as in the ones generated by strict 2PL, because they're conflict serializable. So, where do we have the conflict serializable ones? Well, it's here. And now, though, we start to see things we haven't discussed yet. There's a lot of schedules here, but we haven't seen any examples that will fit into one of those areas. But each of these many areas we can see on this illustration are non-MT, as in, well, the ones that are non-MT. I mean, their schedules, which are conflict serializable, say, without being recoverable, and so on. And on the next slide, I will go through all of these many different cases we haven't seen yet, and show you an example of a schedule which has all of these properties, without having some other subset of them. Like, I will show a schedule that's conflict serializable, but not recoverable. And all around. So, we still need to see quite many examples before we have seen all of the bonds denoted by one of the areas on the previous slide. The first example I want to show you among those is this one. It's serializable, but it's not conflict serializable or recoverable. Why it is serializable? Well, it's because it's view serializable as well. So, what was the requirement from view serializable? You saw them at the first tutorial in this part. Among them was that if you read something that wasn't written by anyone, then you should still read it without anyone having written it in a serial schedule. If you read something someone else wrote, you should still read from the same person, and whoever ends up writing a variable should still end up writing it afterwards. And if you're satisfying all those three requirements, then the two schedules you are looking at are view serializable, view equivalent, and you are view serializable if you are view equivalent to a serial schedules. So, I claim that this schedule here is view equivalent to the serial schedules, which goes one, two, and then transaction three. Why? Well, it's because there's only one read statement here. It's done by transaction three. It's reading something written by transaction two, and that will also be the case in that serial scheduler mentioned with one, two, three. We also see that y end up being written by transaction two, which is also the case here, and x ends up getting written by transaction three, which is also the case in the single schedule one, two, three. However, the schedule y being view serializable and therefore serializable is not conflict serializable because of these two pairs of conflicts. We see that transaction two conflicts with transaction one and transaction one conflicts with transaction two, and therefore we end up having a cycle in our cross-saintance curve when we draw that one, and therefore it's not conflict serializable, as we saw earlier. It's not recoverable either because transaction three reads from transaction two, but transaction three commits before transaction two, and that was the definition of recoverable. Example two is this one. Now, this one is conflict serializable, but it's not recoverable. Why is this conflict serializable? Well, we could draw the precedence curve, but it's easier just to see that it's basically serial if you omit the commit statements, and the commit statements just are the end. So, it's basically serial except for the commit statements, and the conflict serializable, you don't care about the commit statement. However, it's not recoverable precisely for the same reason as before. A transaction three reads from transaction two, but transaction three commits before transaction two. Let's look at another example. This one, example number three, is recoverable and serializable, but not conflict serializable nor cascadeless. It's serializable for the same reason that one was serializable, as in it's view serializable to one, two, three, but it's recoverable, but not conflict serializable nor cascadeless. It's recoverable because the only read operation reads from transaction is done by transaction three and reads from transaction two and two commits before transaction three. It's not conflict serializable similar to schedule one, because of this four operations except same four operations as in example one. And it's not cascadeless, because transaction three reads from transaction two, but the commit statement for transaction two first comes after the read statement for transaction three. Example four is this one. It's recoverable and conflict serializable, but not cascadeless. So, why is it recoverable? Well, the only read operation is done by transaction three again, reading from transaction two, and two commits before transaction three. That's all we need for that one. It's conflict serializable because it's nearly serializable in the same sense as example two, as in it's serial except for the commit statement, and conflict serializable don't care about the commit statement. It's not cascadeless, because, well, basically like in example three, the read operation in transaction three reads Y in transaction two, and transaction two ends up committing after that read operation. Example five is this one. It's cascadeless and serializable, but not conflict serializable. So, why is it cascadeless? Well, the only read operation reads from transaction three reading from transaction two, and transaction two commits before that read operation. So, it's cascadeless. Why is it serializable? Well, it's serializable for the same reason as transaction one was, because it's view serializable to one, two, three. It's not conflict serializable, similar to why example one was not conflict serializable, because of this for operation specifically. So, now we have seen most of the examples. There's only one example left. It's this one, and this example has all the properties except it's not strict 2PL. Why is it not strict 2PL? Well, for instance, you can look at transaction two. It writes 2Y, which was previously written by transaction one. However, transaction one has not committed at the time transaction two writes 2Y, and that's not allowed in a strict schedule. So, the schedule here is not strict, and therefore it cannot be strict two-phase locking either. And that was all these examples I wanted to show you. So, now you can go back to the previous slide and see that at each of these areas that look non-empty on the slide are really non-empty, because at least they contain these schedules. Now we have seen strict two-phase locking schedules, which has a lot of requirements. However, they still allow you to deadlock. Let's see this example here. If you look carefully, it's an example of two strict 2PL schedules, and they still allow you to deadlock. Let's see. First, let's see that they are strict two-phase locking. Well, we have two lock statements, and two sections one, for instance, and they're first unlocked after the commit statement. Again, it's sort of clear that they are two-phase locking, because, well, the locks are clearly before the unlocks. Before the last lock is clearly before the first unlock, because it's before the commit statement. Similarly, in transaction two, the two lock statements are before the commit statements, and the two unlocks are afterwards. Therefore, it's strict two-phase locking. Let's see that this can lead to a deadlock. Let's take the first three database operations from transaction one as a lock, read item x, increase x by 100, and write x. Then let's do the first three database operations from transaction two, which correspond to the first four operations from there, as in lock y, read y, add 100 to y, and write y out. Now, what can we do next? Well, as always before with this deadlock situation, we cannot do anything. We can, for instance, not lock x in transaction two, because the lock is owned by transaction one at this point, and we cannot in transaction one get the lock for y, because transaction two has it. Therefore, we end deadlock. Therefore, we see that even in strict two-phase locking, we might end up in deadlock. So, let me summarize this video. We saw cascade list schedules, which are schedules that ensure you don't get any cascades. They did that by not allowing dirty reads, as in you only allow to read things that was written by someone who has committed already. Instead of implementing that, because it's not that easy to do it with using these locks, we implemented something called strict instead, that had the stronger requirements that you're not allowed to read or overwrite data unless whoever did it last time, as in wrote that data, has already committed. And that led us to strict two PL, which was like two-phase locking. However, you're only allowed to unlock variables for locks that provide data after you have written the commit statement.